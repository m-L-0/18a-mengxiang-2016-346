第二次作业：

# TensorFlow Schoolwork

作业要求：

使用TensorFlow设计K近邻模型，并使用鸢尾花数据集训练、验证模型。



作业思路：

KNN是通过计算不同特征值之间的距离进行分类。

整体的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。

在这里，K的选取很重要：

K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。

核心问题：

KNN算法要解决的核心问题是K值选择，它会直接影响分类结果。

如果选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。

如果选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；



重要步骤：

距离计算在KNN中就显得尤为重要了，这里我采取的是L1距离

#计算L1距离 用L1值寻找最近邻

```python
distance = tf.reduce_sum(tf.abs(tf.add(features_train_placeholder,
tf.negative(features_test_placeholder))), reduction_indices=1)
```

![1544402503584](C:\Users\hasee\AppData\Local\Temp\1544402503584.png)

最后的预测结果也是很可观的